import pandas as pd
import matplotlib.pyplot as plt
import numpy as np # Import numpy for calculations
import os # Import os to check for file existence

# Define the filename for the CSV results (updated for averaged data)
csv_filename = 'saxpy_timing_results_avg.csv'

# --- Check if the CSV file exists ---
if not os.path.exists(csv_filename):
    print(f"Error: The file '{csv_filename}' was not found.")
    print("Please make sure the CSV file is in the same directory as this script,")
    print("and that the latest C code (with averaging) has been compiled and run to generate it.")
    # Exit the script if the file doesn't exist
    exit()

# --- Read the CSV data using pandas ---
try:
    # Read the CSV file into a pandas DataFrame.
    # Assumes the first row is the header matching the averaged C code output.
    df = pd.read_csv(csv_filename)
    # Ensure log2_n column is integer type if needed later, though it should be from CSV
    df['Vector Size (log2 N)'] = df['Vector Size (log2 N)'].astype(int)


except FileNotFoundError:
    print(f"Error: Could not find the file '{csv_filename}'.")
    exit()
except pd.errors.EmptyDataError:
    print(f"Error: The file '{csv_filename}' is empty.")
    exit()
except KeyError as e:
    print(f"Error: Missing expected column in CSV: {e}")
    print("Please ensure the CSV file was generated by the latest C code version")
    print("and uses the 'Avg ...' column names.")
    exit()
except Exception as e:
    print(f"An error occurred while reading the CSV file: {e}")
    exit()

# --- Extract data columns and Calculate Overhead ---
try:
    # Get the 'Vector Size (log2 N)' column for the x-axis.
    log2_n = df['Vector Size (log2 N)']
    # Get the measured time components using the "Avg" names (excluding Cleanup)
    kernel_time = df['Avg Kernel Time (ms)']
    host_alloc_time = df['Avg Host Alloc Time (ms)']
    device_alloc_time = df['Avg Device Alloc Time (ms)']
    host_init_time = df['Avg Host Init Time (ms)']
    h2d_time = df['Avg H2D Time (ms)']
    d2h_time = df['Avg D2H Time (ms)']
    # We still need the cleanup time from the CSV to calculate a more accurate overhead
    # if we want overhead to exclude cleanup. Otherwise, overhead includes cleanup.
    # Let's calculate overhead to include cleanup as before for simplicity.
    # cleanup_time_avg = df['Avg Cleanup Time (ms)'] # Read if needed for specific overhead calc

    # Get the total measured time.
    total_time = df['Avg Total Time (ms)']

    # Calculate the sum of the individually measured components *that we will plot*
    sum_of_plotted_parts = (host_alloc_time + device_alloc_time + host_init_time +
                            h2d_time + kernel_time + d2h_time)

    # Calculate the overhead time (remaining difference from total).
    # This overhead now implicitly includes the average cleanup time measured by C code.
    # Ensure it's not negative due to timer precision issues.
    # Add a small epsilon to avoid issues if overhead is exactly zero on log scale
    epsilon = 1e-9
    overhead_time = np.maximum(epsilon, total_time - sum_of_plotted_parts + epsilon)

    # Define the components to plot as lines (excluding Cleanup)
    components = {
        'Overhead': overhead_time, # Includes avg cleanup + other overhead
        'Device Alloc': device_alloc_time,
        'Host Alloc': host_alloc_time,
        'Host Init': host_init_time,
        'Kernel': kernel_time,
        'D2H Transfer': d2h_time,
        'H2D Transfer': h2d_time,
    }
    # Create labels for the legend (using the "Avg" prefix implicitly)
    component_labels = [f'{label} (ms)' for label in components.keys()]

except KeyError as e:
    # Handle missing columns specifically after trying to access them
    # Update expected columns to use "Avg" prefix
    expected_cols = ['Vector Size (log2 N)', 'Avg Kernel Time (ms)', 'Avg Host Alloc Time (ms)',
                     'Avg Device Alloc Time (ms)', 'Avg Host Init Time (ms)', 'Avg H2D Time (ms)',
                     'Avg D2H Time (ms)', 'Avg Total Time (ms)'] # Removed Avg Cleanup Time (ms) as it's not strictly needed here
    col_name = str(e).strip("'")
    if col_name not in expected_cols and col_name != 'Avg Cleanup Time (ms)': # Ignore missing cleanup col
         print(f"Error: Missing essential column in CSV: {e}")
         print("Please ensure the CSV file was generated by the latest C code version")
         print("and uses the 'Avg ...' column names.")
         exit()
    # If the error was about 'Avg Cleanup Time (ms)', we ignore it.


# --- Create the Line Plot ---
plt.figure(figsize=(12, 7)) # Adjust figure size if needed

# --- Use the 'Paired' or another suitable colormap ---
# Adjust number of colors needed
colors = plt.cm.get_cmap('Paired', len(components))

# Define different markers for better line distinction
markers = ['o', 's', '^', 'd', 'v', '>', '<', 'p'] # Example markers

# Iterate through the components and plot them as lines
for i, (label, data) in enumerate(components.items()):
    # Ensure data is positive for log scale plotting
    plot_data = np.maximum(data, epsilon)
    plt.plot(log2_n, plot_data, marker=markers[i % len(markers)], linestyle='-', label=component_labels[i], color=colors(i))

# --- Add plot labels and title ---
plt.xlabel('Vector Size (log2 N)') # Label for the x-axis
# Set y-axis to logarithmic scale
plt.yscale('log')
plt.ylabel('Time (milliseconds, log scale)') # Updated y-axis label

# --- Adjust Y-axis Limits ---
# Set a minimum value for the y-axis to avoid extreme stretching of near-zero values
min_y_limit = 1e-3 # Set lower limit to 0.001 ms
plt.ylim(bottom=min_y_limit) # Set only the bottom limit

plt.title('SAXPY Avg Execution Time Components vs. Vector Size (Log Scale, No Cleanup)') # Updated Title

# --- Set Integer X-axis Ticks ---
# Determine the range of log2_n values
min_log2_n = log2_n.min()
max_log2_n = log2_n.max()
# Create ticks every 2 units within the range (or adjust step as needed)
step = 2
x_ticks = np.arange(min_log2_n, max_log2_n + 1, step)
# Ensure the last value is included if the step doesn't land on it exactly
# (this might not be necessary if max_log2_n - min_log2_n is divisible by step)
# if x_ticks[-1] < max_log2_n:
#     x_ticks = np.append(x_ticks, max_log2_n) # Optional: force last tick if needed

plt.xticks(x_ticks) # Set the calculated integer ticks

plt.grid(True, which='both', linestyle='--', linewidth=0.5) # Add grid lines for major and minor ticks on log scale
# Place legend outside the plot area to avoid overlap
plt.legend(title="Time Components", loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0.)

# --- Display the plot ---
# Adjust layout to prevent labels overlapping, especially the legend
plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust rect to make space for legend
# Show the plot window.
plt.show()

print(f"Line graph with log scale (integer ticks) generated from '{csv_filename}'.")

